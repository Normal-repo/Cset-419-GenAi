{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.12.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":31260,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport numpy as np\nfrom collections import Counter\nfrom torch.utils.data import Dataset, DataLoader\nfrom nltk.tokenize import word_tokenize\nimport nltk","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:36.250453Z","iopub.execute_input":"2026-02-09T11:13:36.250733Z","iopub.status.idle":"2026-02-09T11:13:41.258438Z","shell.execute_reply.started":"2026-02-09T11:13:36.250708Z","shell.execute_reply":"2026-02-09T11:13:41.257641Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"document = [\"\"\"About the Program\nWhat is the course fee for  Data Science Mentorship Program (DSMP 2023)\nThe course follows a monthly subscription model where you have to make monthly payments of Rs 799/month.\nWhat is the total duration of the course?\nThe total duration of the course is 7 months. So the total course fee becomes 799*7 = Rs 5600(approx.)\nWhat is the syllabus of the mentorship program?\nWe will be covering the following modules:\nPython Fundamentals\nPython libraries for Data Science\nData Analysis\nSQL for Data Science\nMaths for Machine Learning\nML Algorithms\nPractical ML\nMLOPs\nCase studies\nYou can check the detailed syllabus here - https://learnwith.campusx.in/courses/CampusX-Data-Science-Mentorship-Program-637339afe4b0615a1bbed390\nWill Deep Learning and NLP be a part of this program?\nNo, NLP and Deep Learning both are not a part of this program’s curriculum.\nWhat if I miss a live session? Will I get a recording of the session?\nYes all our sessions are recorded, so even if you miss a session you can go back and watch the recording.\nWhere can I find the class schedule?\nCheckout this google sheet to see month by month time table of the course - https://docs.google.com/spreadsheets/d/16OoTax_A6ORAeCg4emgexhqqPv3noQPYKU7RJ6ArOzk/edit?usp=sharing.\nWhat is the time duration of all the live sessions?\nRoughly, all the sessions last 2 hours.\nWhat is the language spoken by the instructor during the sessions?\nHinglish\nHow will I be informed about the upcoming class?\nYou will get a mail from our side before every paid session once you become a paid user.\nCan I do this course if I am from a non-tech background?\nYes, absolutely.\nI am late, can I join the program in the middle?\nAbsolutely, you can join the program anytime.\nIf I join/pay in the middle, will I be able to see all the past lectures?\nYes, once you make the payment you will be able to see all the past content in your dashboard.\nWhere do I have to submit the task?\nYou don’t have to submit the task. We will provide you with the solutions, you have to self evaluate the task yourself.\nWill we do case studies in the program?\nYes.\nWhere can we contact you?\nYou can mail us at nitish.campusx@gmail.com\nPayment/Registration related questions\nWhere do we have to make our payments? Your YouTube channel or website?\nYou have to make all your monthly payments on our website. Here is the link for our website - https://learnwith.campusx.in/\nCan we pay the entire amount of Rs 5600 all at once?\nUnfortunately no, the program follows a monthly subscription model.\nWhat is the validity of monthly subscription? Suppose if I pay on 15th Jan, then do I have to pay again on 1st Feb or 15th Feb\n15th Feb. The validity period is 30 days from the day you make the payment. So essentially you can join anytime you don’t have to wait for a month to end.\nWhat if I don’t like the course after making the payment. What is the refund policy?\nYou get a 7 days refund period from the day you have made the payment.\nI am living outside India and I am not able to make the payment on the website, what should I do?\nYou have to contact us by sending a mail at nitish.campusx@gmail.com\nPost registration queries\nTill when can I view the paid videos on the website?\nThis one is tricky, so read carefully. You can watch the videos till your subscription is valid. Suppose you have purchased subscription on 21st Jan, you will be able to watch all the past paid sessions in the period of 21st Jan to 20th Feb. But after 21st Feb you will have to purchase the subscription again.\nBut once the course is over and you have paid us Rs 5600(or 7 installments of Rs 799) you will be able to watch the paid sessions till Aug 2024.\nWhy lifetime validity is not provided?\nBecause of the low course fee.\nWhere can I reach out in case of a doubt after the session?\nYou will have to fill a google form provided in your dashboard and our team will contact you for a 1 on 1 doubt clearance session\nIf I join the program late, can I still ask past week doubts?\nYes, just select past week doubt in the doubt clearance google form.\nI am living outside India and I am not able to make the payment on the website, what should I do?\nYou have to contact us by sending a mail at nitish.campusx@gmai.com\nCertificate and Placement Assistance related queries\nWhat is the criteria to get the certificate?\nThere are 2 criterias:\nYou have to pay the entire fee of Rs 5600\nYou have to attempt all the course assessments.\nI am joining late. How can I pay payment of the earlier months?\nYou will get a link to pay fee of earlier months in your dashboard once you pay for the current month.\nI have read that Placement assistance is a part of this program. What comes under Placement assistance?\nThis is to clarify that Placement assistance does not mean Placement guarantee. So we dont guarantee you any jobs or for that matter even interview calls. So if you are planning to join this course just for placements, I am afraid you will be disappointed. Here is what comes under placement assistance\nPortfolio Building sessions\nSoft skill sessions\nSessions with industry mentors\nDiscussion on Job hunting strategies\nThe modern world moves at a pace that rarely gives people the chance to slow down and think deeply.\n\nEvery day we consume enormous amounts of information, yet only a small portion of it truly stays with us.\n\nSpeed has become a measure of intelligence, even though understanding usually takes time and repetition.\n\nMany people mistake confusion for failure, when in reality confusion is often the first sign of real learning.\n\nWhen you struggle with an idea, your brain is actively reshaping itself to make room for something new.\n\nThis is why concepts that felt impossible at first can later feel obvious in hindsight.\n\nGrowth does not happen in sudden jumps but through tiny, almost invisible improvements made consistently.\n\nJust like muscles grow during rest after stress, understanding grows after reflection following effort.\n\nComparing your progress to others can hide how far you’ve personally come.\n\nEveryone starts from a different point and moves at a different pace.\n\nTrue mastery is less about memorizing answers and more about recognizing patterns.\n\nAsking good questions often matters more than giving fast answers.\n\nThe ability to sit with uncertainty is a powerful skill in itself.\n\nCreative ideas rarely appear on command; they emerge when the mind is relaxed.\n\nSilence and boredom are not enemies but gateways to deeper thought.\n\nTechnology connects us globally while quietly fragmenting our attention locally.\n\nLearning becomes meaningful when curiosity replaces pressure.\n\nMistakes are not interruptions to progress; they are part of its structure.\n\nPatience turns effort into insight over time.\n\nIn the end, depth always outlasts speed.\nUnderstanding takes time, even when the explanation seems simple.\n\nThe mind needs repetition to turn information into intuition.\n\nRushing through concepts often creates the illusion of progress, not the reality of it.\n\nSlow learning builds stronger foundations than fast memorization.\n\nClarity is usually earned after sustained confusion.\n\nStruggle is not a detour; it is the path itself.\n\nAttention is one of the most valuable resources in the modern age.\n\nWhat you focus on repeatedly shapes how you think.\n\nDistractions don’t just steal time, they steal depth.\n\nConsistency matters more than intensity in the long run.\n\nSmall daily effort compounds into significant growth.\n\nBreaks are not wasted time; they reset perspective.\n\nCuriosity keeps learning alive long after motivation fades.\n\nUnderstanding “why” creates flexibility beyond knowing “how.”\n\nReal confidence comes from experience, not speed.\n\nComplex ideas become simple only after being fully understood.\n\nThe best insights often arrive when you stop forcing them.\n\nThinking deeply is becoming a rare and valuable skill.\n\nQuestions open doors that answers sometimes close.\n\nProgress feels slow while it’s happening but fast when you look back.\n\nLearning is not about finishing, it’s about becoming.\nI didn’t think it would take this long.\n\nNothing important ever finishes quickly.\n\nStill, everyone else makes it look easy.\n\nThey only show the clean parts.\n\nSo the struggle is normal then?\n\nMore normal than success stories admit.\n\nI keep thinking I should already understand this.\n\nUnderstanding usually comes after you stop rushing it.\n\nThat’s hard when time feels tight.\n\nTime feels tight when pressure is loud.\n\nWhat if I’m just not good at this?\n\nThat thought shows up right before progress.\n\nYou’re saying doubt isn’t a bad sign?\n\nIt’s usually a sign you care.\n\nI wish I could see the end clearly.\n\nMost people don’t until they’re almost there.\n\nSo I just keep going?\n\nYou keep going, but you also slow down.\n\nThat sounds contradictory.\n\nLearning usually is.\n\nWhen does it start feeling easier?\n\nWhen you stop measuring every step.\n\nAnd if I mess up again?\n\nThen you’ll have more data than before.\n\nThat actually makes it sound manageable.\n\nThat’s because it is.\nI didn’t expect today to feel this heavy.\n\nSome days carry more thoughts than others.\n\nIt started with one small mistake.\n\nThose tend to grow louder in your head.\n\nI kept replaying it again and again.\n\nYour brain thinks repetition equals control.\n\nIt definitely didn’t feel like control.\n\nThat’s because reflection and rumination look similar but feel different.\n\nHow do you tell them apart?\n\nOne helps you learn, the other just drains you.\n\nI think I’ve been stuck in the draining one.\n\nThen maybe it’s time to change the question you’re asking yourself.\n\nWhat should I ask instead?\n\nAsk what you can try differently next time.\n\nThat sounds more constructive already.\n\nSmall shifts can calm loud thoughts.\n\nDo you ever stop doubting yourself completely?\n\nNot completely, but you learn to walk with doubt instead of fighting it.\n\nThat sounds oddly peaceful.\n\nIt is, once you stop expecting certainty.\n\nI always thought confidence meant zero fear.\n\nConfidence usually just means moving despite fear.\n\nSo everyone’s just pretending to be sure?\n\nMost people are just pretending to be calm.\n\nThat actually makes me feel less alone.\n\nYou were never as alone as you thought.\n\nI wish someone had said that earlier.\n\nSometimes you only hear things when you’re ready.\n\nMaybe today was the right time then.\n\nMaybe today was exactly when you needed it.\nI thought I was the only one feeling stuck.\n\nEveryone feels stuck; some just hide it better.\n\nIt’s weird how silence makes problems feel bigger.\n\nTalking about them shrinks them a little.\n\nDo you ever feel like quitting midway?\n\nMore times than I can count.\n\nWhat makes you continue then?\n\nUsually curiosity beats frustration eventually.\n\nI wish my curiosity was louder.\n\nIt gets louder when you stop judging yourself.\n\nThat’s easier said than done.\n\nMost helpful things are.\n\nDo you think progress is obvious when it happens?\n\nNot really, it’s only obvious when you look back.\n\nSo maybe I’m improving without noticing.\n\nThat’s usually how growth works.\n\nI keep waiting for a big breakthrough moment.\n\nBreakthroughs are often tiny realizations stacked together.\n\nAnd what about days when nothing works?\n\nThose days teach patience more than skill.\n\nI hate being patient though.\n\nNobody enjoys it, but everyone needs it.\n\nDo you think effort always pays off?\n\nEffort always changes you, even if results take time.\n\nThat’s actually comforting to hear.\n\nGood, because you’re doing better than you think.\n\"\"\"\n           ]\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:41.259937Z","iopub.execute_input":"2026-02-09T11:13:41.260286Z","iopub.status.idle":"2026-02-09T11:13:41.270330Z","shell.execute_reply.started":"2026-02-09T11:13:41.260262Z","shell.execute_reply":"2026-02-09T11:13:41.269694Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"raw_text=document[0]\n\nline=raw_text.splitlines()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:41.271087Z","iopub.execute_input":"2026-02-09T11:13:41.271338Z","iopub.status.idle":"2026-02-09T11:13:41.285976Z","shell.execute_reply.started":"2026-02-09T11:13:41.271317Z","shell.execute_reply":"2026-02-09T11:13:41.285259Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"from tqdm import tqdm","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:41.287674Z","iopub.execute_input":"2026-02-09T11:13:41.287950Z","iopub.status.idle":"2026-02-09T11:13:41.297077Z","shell.execute_reply.started":"2026-02-09T11:13:41.287929Z","shell.execute_reply":"2026-02-09T11:13:41.296386Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"sentences=[]\nfor i in tqdm(line):\n    line=i.strip()\n    if line:\n        sentences.append(line.lower())","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:41.297949Z","iopub.execute_input":"2026-02-09T11:13:41.298395Z","iopub.status.idle":"2026-02-09T11:13:41.309909Z","shell.execute_reply.started":"2026-02-09T11:13:41.298374Z","shell.execute_reply":"2026-02-09T11:13:41.309264Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 318/318 [00:00<00:00, 1437272.28it/s]\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer()\ntokenizer.fit_on_texts(document)\n\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:41.310750Z","iopub.execute_input":"2026-02-09T11:13:41.311031Z","iopub.status.idle":"2026-02-09T11:13:54.602710Z","shell.execute_reply.started":"2026-02-09T11:13:41.311000Z","shell.execute_reply":"2026-02-09T11:13:54.602097Z"}},"outputs":[{"name":"stderr","text":"2026-02-09 11:13:42.905156: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:467] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1770635623.087994      55 cuda_dnn.cc:8579] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1770635623.145856      55 cuda_blas.cc:1407] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nW0000 00:00:1770635623.602242      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770635623.602282      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770635623.602285      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\nW0000 00:00:1770635623.602287      55 computation_placer.cc:177] computation placer already registered. Please check linkage and avoid linking the same target more than once.\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"sentences[1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.603495Z","iopub.execute_input":"2026-02-09T11:13:54.603974Z","iopub.status.idle":"2026-02-09T11:13:54.609232Z","shell.execute_reply.started":"2026-02-09T11:13:54.603949Z","shell.execute_reply":"2026-02-09T11:13:54.608502Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"'what is the course fee for  data science mentorship program (dsmp 2023)'"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"sen=[]\n\nfor i in tqdm(sentences):\n    line=tokenizer.texts_to_sequences([i])[0]\n    sen.append(line)\n\ntotal_words=len(tokenizer.word_index)+1","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.610228Z","iopub.execute_input":"2026-02-09T11:13:54.610894Z","iopub.status.idle":"2026-02-09T11:13:54.831480Z","shell.execute_reply.started":"2026-02-09T11:13:54.610861Z","shell.execute_reply":"2026-02-09T11:13:54.830912Z"}},"outputs":[{"name":"stderr","text":"100%|██████████| 200/200 [00:00<00:00, 84392.43it/s]\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"total_words","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.832295Z","iopub.execute_input":"2026-02-09T11:13:54.832556Z","iopub.status.idle":"2026-02-09T11:13:54.839051Z","shell.execute_reply.started":"2026-02-09T11:13:54.832534Z","shell.execute_reply":"2026-02-09T11:13:54.838380Z"}},"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"665"},"metadata":{}}],"execution_count":9},{"cell_type":"code","source":"sen[0]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.841067Z","iopub.execute_input":"2026-02-09T11:13:54.841377Z","iopub.status.idle":"2026-02-09T11:13:54.851487Z","shell.execute_reply.started":"2026-02-09T11:13:54.841356Z","shell.execute_reply":"2026-02-09T11:13:54.851016Z"}},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"[38, 1, 23]"},"metadata":{}}],"execution_count":10},{"cell_type":"code","source":"max_len=0\n\nmax_len=max(len(x) for x in sen)\n\nmax_len","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.852068Z","iopub.execute_input":"2026-02-09T11:13:54.852238Z","iopub.status.idle":"2026-02-09T11:13:54.862708Z","shell.execute_reply.started":"2026-02-09T11:13:54.852221Z","shell.execute_reply":"2026-02-09T11:13:54.862015Z"}},"outputs":[{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"57"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"from tensorflow.keras.preprocessing.sequence import pad_sequences","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.863567Z","iopub.execute_input":"2026-02-09T11:13:54.863849Z","iopub.status.idle":"2026-02-09T11:13:54.871535Z","shell.execute_reply.started":"2026-02-09T11:13:54.863821Z","shell.execute_reply":"2026-02-09T11:13:54.870995Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"train_seq=[]\ninput_seq=[]\noutput_word=[]\nfor i in sen:\n    for j in range(1,len(i)):\n        train_seq.append(i[:j+1])\ntrain_seq=pad_sequences(train_seq,maxlen=max_len,padding=\"pre\")\n\ninput_seq,output_word=train_seq[:,:-1],train_seq[:,-1]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.872279Z","iopub.execute_input":"2026-02-09T11:13:54.872497Z","iopub.status.idle":"2026-02-09T11:13:54.885178Z","shell.execute_reply.started":"2026-02-09T11:13:54.872465Z","shell.execute_reply":"2026-02-09T11:13:54.884519Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"x=torch.tensor(input_seq,dtype=torch.long)\ny=torch.tensor(output_word,dtype=torch.long)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.886052Z","iopub.execute_input":"2026-02-09T11:13:54.886323Z","iopub.status.idle":"2026-02-09T11:13:54.921844Z","shell.execute_reply.started":"2026-02-09T11:13:54.886297Z","shell.execute_reply":"2026-02-09T11:13:54.921154Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\nx.shape","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.922875Z","iopub.execute_input":"2026-02-09T11:13:54.923081Z","iopub.status.idle":"2026-02-09T11:13:54.927702Z","shell.execute_reply.started":"2026-02-09T11:13:54.923062Z","shell.execute_reply":"2026-02-09T11:13:54.927097Z"}},"outputs":[{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"torch.Size([1749, 56])"},"metadata":{}}],"execution_count":15},{"cell_type":"code","source":"x","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.928427Z","iopub.execute_input":"2026-02-09T11:13:54.928656Z","iopub.status.idle":"2026-02-09T11:13:54.972762Z","shell.execute_reply.started":"2026-02-09T11:13:54.928632Z","shell.execute_reply":"2026-02-09T11:13:54.972223Z"}},"outputs":[{"execution_count":16,"output_type":"execute_result","data":{"text/plain":"tensor([[  0,   0,   0,  ...,   0,   0,  38],\n        [  0,   0,   0,  ...,   0,  38,   1],\n        [  0,   0,   0,  ...,   0,   0,   8],\n        ...,\n        [  0,   0,   0,  ..., 120, 664, 294],\n        [  0,   0,   0,  ..., 664, 294,  31],\n        [  0,   0,   0,  ..., 294,  31,   2]])"},"metadata":{}}],"execution_count":16},{"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self,x,y):\n        self.X=x\n        self.y=y\n\n    def __len__(self):\n        return self.X.shape[0]\n    def __getitem__(self,idx):\n        return self.X[idx] ,self.y[idx]","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.973565Z","iopub.execute_input":"2026-02-09T11:13:54.973922Z","iopub.status.idle":"2026-02-09T11:13:54.977894Z","shell.execute_reply.started":"2026-02-09T11:13:54.973889Z","shell.execute_reply":"2026-02-09T11:13:54.977233Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"dataset=CustomDataset(x,y)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.978676Z","iopub.execute_input":"2026-02-09T11:13:54.978901Z","iopub.status.idle":"2026-02-09T11:13:54.988408Z","shell.execute_reply.started":"2026-02-09T11:13:54.978872Z","shell.execute_reply":"2026-02-09T11:13:54.987853Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"dataloader=DataLoader(dataset,batch_size=32,shuffle=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:13:54.989358Z","iopub.execute_input":"2026-02-09T11:13:54.989800Z","iopub.status.idle":"2026-02-09T11:13:54.998749Z","shell.execute_reply.started":"2026-02-09T11:13:54.989779Z","shell.execute_reply":"2026-02-09T11:13:54.998149Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"class LSTMModel(nn.Module):\n\n  def __init__(self, vocab_size):\n    super().__init__()\n    self.embedding = nn.Embedding(vocab_size, 128)\n    self.lstm = nn.LSTM(128, 128, batch_first=True)\n    self.fc = nn.Linear(128, vocab_size)\n\n  def forward(self, x):\n    embedded = self.embedding(x)\n    intermediate_hidden_states, (final_hidden_state, final_cell_state) = self.lstm(embedded)\n    output = self.fc(final_hidden_state.squeeze(0))\n    return output  ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:29:27.833537Z","iopub.execute_input":"2026-02-09T11:29:27.833850Z","iopub.status.idle":"2026-02-09T11:29:27.838881Z","shell.execute_reply.started":"2026-02-09T11:29:27.833825Z","shell.execute_reply":"2026-02-09T11:29:27.838038Z"}},"outputs":[],"execution_count":55},{"cell_type":"code","source":"model = LSTMModel(total_words).to(device)\n\nif torch.cuda.device_count() > 1:\n    print(\"Using\", torch.cuda.device_count(), \"GPUs!\")\n    model = torch.nn.DataParallel(model)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:29:29.698915Z","iopub.execute_input":"2026-02-09T11:29:29.699542Z","iopub.status.idle":"2026-02-09T11:29:29.708194Z","shell.execute_reply.started":"2026-02-09T11:29:29.699512Z","shell.execute_reply":"2026-02-09T11:29:29.707636Z"}},"outputs":[{"name":"stdout","text":"Using 2 GPUs!\n","output_type":"stream"}],"execution_count":56},{"cell_type":"code","source":"from torch.nn.parallel import DistributedDataParallel as DDP","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:29:31.851066Z","iopub.execute_input":"2026-02-09T11:29:31.851646Z","iopub.status.idle":"2026-02-09T11:29:31.854858Z","shell.execute_reply.started":"2026-02-09T11:29:31.851620Z","shell.execute_reply":"2026-02-09T11:29:31.854119Z"}},"outputs":[],"execution_count":57},{"cell_type":"code","source":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:29:33.400024Z","iopub.execute_input":"2026-02-09T11:29:33.400607Z","iopub.status.idle":"2026-02-09T11:29:33.403881Z","shell.execute_reply.started":"2026-02-09T11:29:33.400563Z","shell.execute_reply":"2026-02-09T11:29:33.403306Z"}},"outputs":[],"execution_count":58},{"cell_type":"code","source":"epochs = 500\nlearning_rate = 0.001\n\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:29:34.872212Z","iopub.execute_input":"2026-02-09T11:29:34.873092Z","iopub.status.idle":"2026-02-09T11:29:34.877590Z","shell.execute_reply.started":"2026-02-09T11:29:34.873049Z","shell.execute_reply":"2026-02-09T11:29:34.876859Z"}},"outputs":[],"execution_count":59},{"cell_type":"code","source":"for i in range(epochs):\n    total_loss=0\n    for x,y in tqdm(dataloader):\n        x,y=x.to(device),y.to(device)\n\n        optimizer.zero_grad()\n\n        output=model(x)\n        loss=criterion(output,y)\n\n        loss.backward()\n\n        optimizer.step()\n        total_loss = total_loss + loss.item()\n    print(f\"Epoch: {i + 1}, Loss: {total_loss:.4f}\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import torch\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\ndef prediction(model, tokenizer, text, max_len, device):\n    model.eval()\n\n    # tokenize text\n    seq = tokenizer.texts_to_sequences([text])\n\n    # pad sequence\n    seq = pad_sequences(seq, maxlen=max_len, padding=\"pre\")\n\n    # convert to tensor\n    x = torch.tensor(seq, dtype=torch.long).to(device)\n\n    with torch.no_grad():\n        output = model(x)\n\n    # get predicted index\n    _, index = torch.max(output, dim=1)\n    predicted_id = index.item()\n\n    # index → word\n    word = tokenizer.index_word.get(predicted_id, \"<UNK>\")\n\n    return word\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:32:46.256319Z","iopub.execute_input":"2026-02-09T11:32:46.256652Z","iopub.status.idle":"2026-02-09T11:32:46.262259Z","shell.execute_reply.started":"2026-02-09T11:32:46.256621Z","shell.execute_reply":"2026-02-09T11:32:46.261644Z"}},"outputs":[],"execution_count":61},{"cell_type":"code","source":"import time\n\nnum_tokens = 10\ninput_text = \"hi how are\"\n\nfor i in range(num_tokens):\n    next_word = prediction(model, tokenizer, input_text, max_len, device)\n\n    # append instead of overwrite\n    input_text = input_text + \" \" + next_word\n\n    print(input_text)\n    time.sleep(0.5)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:32:48.101058Z","iopub.execute_input":"2026-02-09T11:32:48.101326Z","iopub.status.idle":"2026-02-09T11:32:53.125633Z","shell.execute_reply.started":"2026-02-09T11:32:48.101301Z","shell.execute_reply":"2026-02-09T11:32:53.125072Z"}},"outputs":[{"name":"stdout","text":"hi how are i\nhi how are i have\nhi how are i have read\nhi how are i have read that\nhi how are i have read that placement\nhi how are i have read that placement assistance\nhi how are i have read that placement assistance is\nhi how are i have read that placement assistance is a\nhi how are i have read that placement assistance is a part\nhi how are i have read that placement assistance is a part of\n","output_type":"stream"}],"execution_count":62},{"cell_type":"code","source":"dataloader1 = DataLoader(dataset, batch_size=32, shuffle=False)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:28:53.620052Z","iopub.execute_input":"2026-02-09T11:28:53.620268Z","iopub.status.idle":"2026-02-09T11:28:53.623537Z","shell.execute_reply.started":"2026-02-09T11:28:53.620248Z","shell.execute_reply":"2026-02-09T11:28:53.622996Z"}},"outputs":[],"execution_count":53},{"cell_type":"code","source":"def calculate_accuracy(model, dataloader, device):\n    model.eval()  # Set the model to evaluation mode\n    correct = 0\n    total = 0\n\n    with torch.no_grad():  # No need to compute gradients\n        for batch_x, batch_y in dataloader1:\n            batch_x, batch_y = batch_x.to(device), batch_y.to(device)\n\n            # Get model predictions\n            outputs = model(batch_x)\n\n            # Get the predicted word indices\n            _, predicted = torch.max(outputs, dim=1)\n\n            # Compare with actual labels\n            correct += (predicted == batch_y).sum().item()\n            total += batch_y.size(0)\n\n    accuracy = correct / total * 100\n    return accuracy\n\n# Compute accuracy\naccuracy = calculate_accuracy(model, dataloader, device)\nprint(f\"Model Accuracy: {accuracy:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-02-09T11:33:19.628456Z","iopub.execute_input":"2026-02-09T11:33:19.629160Z","iopub.status.idle":"2026-02-09T11:33:19.801963Z","shell.execute_reply.started":"2026-02-09T11:33:19.629128Z","shell.execute_reply":"2026-02-09T11:33:19.801395Z"}},"outputs":[{"name":"stdout","text":"Model Accuracy: 93.88%\n","output_type":"stream"}],"execution_count":63}]}